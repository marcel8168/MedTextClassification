{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███████                                                                                                                                                                                            | 3869/105930 [00:00<00:05, 19459.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing medical field: human_medicine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████████████████████████████▍                                                                                                                                   | 34093/105930 [00:03<00:05, 12965.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing medical field: veterinary_medicine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105930/105930 [00:10<00:00, 10063.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from Source_code.z_utils.data_preparing import split_data\n",
    "from Source_code.z_utils.data_preprocessing import xml_to_df\n",
    "from Source_code.z_utils.global_constants import RANDOM_SEED\n",
    "\n",
    "\n",
    "datasets = [\"human_medical_data/\", \"veterinary_medical_data/\"]\n",
    "data_path = \"./data/\"\n",
    "xml_files = []\n",
    "for folder in datasets:\n",
    "    xml_files.append([f\"{data_path}{folder}{xml}\" for xml in os.listdir(data_path + folder)])\n",
    "\n",
    "hum_df, vet_df = xml_to_df(xml_files)\n",
    "\n",
    "# balance case reports and other text types\n",
    "vet_case_rep = vet_df[vet_df['text_types'].apply(lambda x: \"Case Reports\" in x)].sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "max_num = len(vet_case_rep)\n",
    "vet_jour_art = vet_df[vet_df['text_types'].apply(lambda x: \"Case Reports\" not in x)].sample(max_num, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "hum_case_rep = hum_df[hum_df['text_types'].apply(lambda x: \"Case Reports\" in x)].sample(max_num, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "hum_jour_art = hum_df[hum_df['text_types'].apply(lambda x: \"Case Reports\" not in x)].sample(max_num, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "\n",
    "train_set_case_rep, val_set_case_rep, test_set_case_rep = split_data(hum_case_rep, vet_case_rep)\n",
    "train_set_jour_art, val_set_jour_art, test_set_jour_art = split_data(hum_jour_art, vet_jour_art)\n",
    "\n",
    "train_set = pd.concat([train_set_case_rep, train_set_jour_art]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "val_set = pd.concat([val_set_case_rep, val_set_jour_art]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "test_set = pd.concat([test_set_case_rep, test_set_jour_art]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True, inplace=False)\n",
    "\n",
    "train_set[\"title_abstract\"] = train_set[[\"title\", \"abstract\"]].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "val_set[\"title_abstract\"] = val_set[[\"title\", \"abstract\"]].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_set[\"title_abstract\"] = test_set[[\"title\", \"abstract\"]].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "-------------\n",
      "Training set: (38360, 7)\n",
      "Validation set: (4796, 7)\n",
      "Test set: (4796, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes\")\n",
    "print(\"-------------\")\n",
    "print(f\"Training set: {train_set.shape}\")\n",
    "print(f\"Validation set: {val_set.shape}\")\n",
    "print(f\"Test set: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance\n",
      "-------------\n",
      "Training set: 0.5\n",
      "Validation set: 0.5\n",
      "Test set: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance\")\n",
    "print(\"-------------\")\n",
    "print(f\"Training set: {train_set.labels.describe().loc['mean']}\")\n",
    "print(f\"Validation set: {val_set.labels.describe().loc['mean']}\")\n",
    "print(f\"Test set: {test_set.labels.describe().loc['mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[[\"pmid\", \"text_types\", \"title\", \"abstract\", \"title_abstract\", \"meshtermlist\", \"labels\"]].to_json('train.json', orient='records')\n",
    "val_set[[\"pmid\", \"text_types\", \"title\", \"abstract\", \"title_abstract\", \"meshtermlist\", \"labels\"]].to_json('valid.json', orient='records')\n",
    "test_set[[\"pmid\", \"text_types\", \"title\", \"abstract\", \"title_abstract\", \"meshtermlist\", \"labels\"]].to_json('test.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
