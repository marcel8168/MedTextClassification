{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of word importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"bert\":{\"slug\": \"bert-base-uncased-pubmed\", \"file_name\":\"bert-base-uncased.pt\"},\n",
    "    \"roberta\":{\"slug\": \"roberta-base-pubmed\", \"file_name\":\"roberta-base.pt\"},\n",
    "    \"deberta\":{\"slug\": \"deberta-base-pubmed\", \"file_name\":\"deberta-base.pt\"},\n",
    "    \"bluebert\":{\"slug\": \"bluebert-large-pubmed\", \"file_name\":\"bluebert_pubmed_uncased_L-24_H-1024_A-16.pt\"},\n",
    "    \"xlnet\":{\"slug\": \"xlnet-large-pubmed\", \"file_name\":\"xlnet-large-cased.pt\"},\n",
    "    \"svm\":{\"slug\":\"svm-linear-pubmed\", \"file_name\":[\"svm.pkl\", \"vectorizer.pkl\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert loaded.\n",
      "roberta loaded.\n",
      "deberta loaded.\n",
      "bluebert loaded.\n",
      "xlnet loaded.\n",
      "Downloading svm-linear-pubmed.tar.gz to ./models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36.4M/36.4M [00:02<00:00, 17.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm loaded.\n",
      "vectorizer loaded.\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "from Source_code.z_utils.BERTClassifier import BERTClassifier\n",
    "from Source_code.z_utils.RoBERTaClassifier import RoBERTaClassifier\n",
    "from Source_code.z_utils.DeBERTaClassifier import DeBERTaClassifier\n",
    "from Source_code.z_utils.BlueBERTClassifier import BlueBERTClassifier\n",
    "from Source_code.z_utils.XLNetClassifier import XLNetClassifier\n",
    "\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "data_path = \"./models/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    print(f\"Directory created: {data_path}\")\n",
    "models = {}\n",
    "\n",
    "for model in model_names.keys():\n",
    "    file_name = model_names[model][\"file_name\"]\n",
    "    target_path = f\"{data_path}{file_name}\"\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        slug = model_names[model][\"slug\"]\n",
    "        if model == \"svm\":\n",
    "            kaggle.api.model_instance_version_download_cli(f\"marcelhiltner/{slug}/scikitlearn/{slug}/1\", data_path, untar=True)\n",
    "        else:\n",
    "            kaggle.api.model_instance_version_download_cli(f\"marcelhiltner/{slug}/pytorch/{slug}/1\", data_path, untar=True)\n",
    "        \n",
    "    if model == \"svm\":\n",
    "        svm = joblib.load(f\"{data_path}{file_name[0]}\")\n",
    "        print(\"svm loaded.\")\n",
    "        vectorizer = joblib.load(f\"{data_path}{file_name[1]}\")\n",
    "        print(\"vectorizer loaded.\")\n",
    "        models[model] = (svm, vectorizer)\n",
    "    else:\n",
    "        models[model] = torch.load(target_path)\n",
    "        models[model].eval()\n",
    "        print(f\"{model} loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 435.7 kB/s eta 0:00:30\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 0.7/12.8 MB 3.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 8.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.4/12.8 MB 13.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.9/12.8 MB 15.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 17.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 19.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.5/12.8 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.4/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\albbl\\documents\\studium\\11_semester\\appendix_code\\.venv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prediction functions aligned to LIME functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Source_code.z_utils.global_constants import MAX_LEN\n",
    "\n",
    "\n",
    "def predict_proba_plm(texts):\n",
    "    \"\"\"\n",
    "    Predicts class probabilities for the given texts using PLM classifier.\n",
    "\n",
    "    Args:\n",
    "        texts (array-like): List or array containing text data.\n",
    "\n",
    "    Returns:\n",
    "        array: Array of predicted class probabilities.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for data in texts:\n",
    "        text = str(data)\n",
    "\n",
    "        inputs = model.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs.to(device))\n",
    "\n",
    "        probabilities = F.softmax(\n",
    "            logits.squeeze(), -1).cpu().detach().numpy().tolist()\n",
    "        predictions.append(probabilities)\n",
    "        \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_svm(texts):\n",
    "    \"\"\"\n",
    "    Predicts class probabilities for the given texts using SVM classifier.\n",
    "\n",
    "    Args:\n",
    "        texts (array-like): List or array containing text data.\n",
    "\n",
    "    Returns:\n",
    "        array: Array of predicted class probabilities.\n",
    "    \"\"\"\n",
    "    vectorized_texts = vectorizer.transform(texts)\n",
    "    decision = svm.decision_function(vectorized_texts)\n",
    "    reshaped_decision = np.array(decision).reshape(-1, 1)\n",
    "\n",
    "    return reshaped_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_text\n",
    "\n",
    "from Source_code.z_utils.data_preprocessing import preprocess_text\n",
    "from Source_code.z_utils.global_constants import LABELS_MAP, RANDOM_SEED\n",
    "from Source_code.z_utils.lemmatize import lemmatize\n",
    "\n",
    "\n",
    "class_names = LABELS_MAP.keys()\n",
    "explainer = lime.lime_text.LimeTextExplainer(class_names=class_names, random_state=RANDOM_SEED, verbose=True)\n",
    "text = 'Physicians and veterinarians often encounter cases where human and animal health intersect. For instance, consider zoonotic diseases like rabies, where humans can contract the virus from infected animals. Additionally, advancements in medical technology have led to the use of animal models for studying human diseases, such as cancer research using mice. Furthermore, the One Health approach emphasizes the interconnectedness of human, animal, and environmental health, highlighting the importance of collaboration between medical and veterinary professionals.'\n",
    "text_prep = preprocess_text(text)\n",
    "\n",
    "for model_key in models.keys():\n",
    "    model = models[model_key]\n",
    "    \n",
    "    print(\"=\" * 30)\n",
    "    print(f'Model {model_key}')\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if model_key == \"svm\":\n",
    "        lemmatizer = spacy.load('en_core_web_sm')\n",
    "        proc_text = preprocess_text(text_prep, numbers=True)\n",
    "        lemm_text = lemmatize(lemmatizer, proc_text)\n",
    "        exp = explainer.explain_instance(lemm_text, predict_proba_svm, labels=(0,), num_features=25, num_samples=500)\n",
    "        exp.save_to_file(f\"interpretation_svm.html\")\n",
    "    else:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        exp = explainer.explain_instance(text_prep, predict_proba_plm, num_features=25, num_samples=500)\n",
    "        exp.save_to_file(f\"interpretation_{model.checkpoint[model.checkpoint.find('/')+1:]}.html\")\n",
    "    \n",
    "    exp.show_in_notebook(text=text_prep)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
