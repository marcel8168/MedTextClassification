{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, SVM and vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import os\n",
    "\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "data_path = \"./corpus/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    print(f\"Directory created: {data_path}\")\n",
    "    \n",
    "kaggle.api.dataset_download_files('marcelhiltner/pubmed-human-veterinary-medicine-classification', path=data_path, unzip=True)\n",
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from Source_code.z_utils.lemmatize import lemmatize\n",
    "\n",
    "\n",
    "try:\n",
    "    lemmatizer = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    train_set = pd.read_json(f\"{data_path}train.json\", orient=\"records\")\n",
    "    train_set[\"title_abstract\"] = train_set[\"title_abstract\"].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    train_set[\"title_abstract\"] = train_set[\"title_abstract\"].apply(lambda x: lemmatize(lemmatizer, x))\n",
    "    print(\"Data loaded successfully: train.json\")\n",
    "    print(f\"Shape: {train_set.shape}\")\n",
    "    \n",
    "    val_set = pd.read_json(f\"{data_path}valid.json\", orient=\"records\")\n",
    "    val_set[\"title_abstract\"] = val_set[\"title_abstract\"].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    val_set[\"title_abstract\"] = val_set[\"title_abstract\"].apply(lambda x: lemmatize(lemmatizer, x))\n",
    "    print(\"Data loaded successfully: valid.json\")\n",
    "    print(f\"Shape: {val_set.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "from Source_code.z_utils.global_constants import *\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                ngram_range=(1, 3),\n",
    "                strip_accents=\"ascii\",\n",
    "                lowercase=True,\n",
    "                max_features=38000,\n",
    "                )\n",
    "\n",
    "train_x = vectorizer.fit_transform(train_set[\"title_abstract\"])\n",
    "train_y = train_set[\"labels\"]\n",
    "\n",
    "if not os.path.exists(PATH_SAVED_MODELS):\n",
    "    os.makedirs(PATH_SAVED_MODELS)\n",
    "joblib.dump(vectorizer, f\"{PATH_SAVED_MODELS}{vectorizer}.pkl\")\n",
    "\n",
    "val_x = vectorizer.transform(val_set[\"title_abstract\"])\n",
    "val_y = val_set[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "from Source_code.z_utils.global_constants import *\n",
    "\n",
    "MODEL_CHECKPOINT = \"svm\"\n",
    "\n",
    "time0 = time.monotonic_ns()\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "svm = LinearSVC(random_state=RANDOM_SEED, dual=False, max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=10, scoring='accuracy', verbose=4, return_train_score=True)\n",
    "result = grid_search.fit(train_x, train_y)\n",
    "best_svm = result.best_estimator_\n",
    "\n",
    "if not os.path.exists(PATH_SAVED_MODELS):\n",
    "    os.makedirs(PATH_SAVED_MODELS)\n",
    "joblib.dump(best_svm, f\"{PATH_SAVED_MODELS}{MODEL_CHECKPOINT}.pkl\")\n",
    "\n",
    "elapsed_time = datetime.timedelta(microseconds=(time.monotonic_ns() - time0)/1000)\n",
    "\n",
    "if not os.path.exists(PATH_SAVED_METRICS):\n",
    "    os.makedirs(PATH_SAVED_METRICS)\n",
    "with open(f\"{PATH_SAVED_METRICS}run_times_{MODEL_CHECKPOINT}.json\", \"w\") as outfile:\n",
    "    json.dump({\"total_time\": str(elapsed_time), \"refit_time\": result.refit_time_}, outfile)\n",
    "pd.DataFrame(result.cv_results_).to_json(f\"{PATH_SAVED_METRICS}cv_results_{MODEL_CHECKPOINT}.json\")\n",
    "with open(f\"{PATH_SAVED_METRICS}best_values_{MODEL_CHECKPOINT}.json\", \"w\") as outfile:\n",
    "    json.dump({\"best_acc\": result.best_score_, \"best_params\": result.best_params_}, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy of training and validation depending on C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "param_C_values = [param['C'] for param in result.cv_results_[\"params\"]]\n",
    "split_train_scores = [result.cv_results_[f\"split{i}_train_score\"] for i in range(10)]\n",
    "\n",
    "for i, split_train_score in enumerate(split_train_scores):\n",
    "    plt.plot(param_C_values, split_train_score, label=f\"Split {i + 1}\")\n",
    "\n",
    "mean_train_scores = result.cv_results_[\"mean_train_score\"]\n",
    "plt.plot(param_C_values, mean_train_scores, marker=\"o\", linestyle=\"-\", color=\"black\", label=\"Mean Train Score\")\n",
    "\n",
    "best_c = result.best_params_[\"C\"]\n",
    "plt.scatter(best_c, mean_train_scores[result.best_index_], color=\"red\", label=f\"Best C = {best_c}\", zorder=5)\n",
    "\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"Train_Accuracy_for_Different_C_Values_{MODEL_CHECKPOINT}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.title(\"Train Accuracy for Different C Values\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_scores = [result.cv_results_[f\"split{i}_test_score\"] for i in range(10)]\n",
    "\n",
    "for i, split_test_score in enumerate(split_test_scores):\n",
    "    plt.plot(param_C_values, split_test_score, label=f\"Split {i + 1}\")\n",
    "\n",
    "mean_test_scores = result.cv_results_[\"mean_test_score\"]\n",
    "plt.plot(param_C_values, mean_test_scores, marker=\"o\", linestyle=\"-\", color=\"black\", label=\"Mean Test Score\")\n",
    "\n",
    "plt.scatter(best_c, mean_test_scores[result.best_index_], color=\"red\", label=f\"Best C = {best_c}\", zorder=5)\n",
    "\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"Validation_Accuracy_for_Different_C_Values_{MODEL_CHECKPOINT}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.title(\"Test Accuracy for Different C Values\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
